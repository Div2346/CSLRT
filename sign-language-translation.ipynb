{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8319196,"sourceType":"datasetVersion","datasetId":4941359}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T01:49:16.241294Z","iopub.execute_input":"2024-05-13T01:49:16.241980Z","iopub.status.idle":"2024-05-13T01:49:16.553414Z","shell.execute_reply.started":"2024-05-13T01:49:16.241943Z","shell.execute_reply":"2024-05-13T01:49:16.552505Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/gloss2sent/gloss2sent.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:49:17.802023Z","iopub.execute_input":"2024-05-13T01:49:17.802582Z","iopub.status.idle":"2024-05-13T01:49:29.607354Z","shell.execute_reply.started":"2024-05-13T01:49:17.802549Z","shell.execute_reply":"2024-05-13T01:49:29.606561Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-13 01:49:19.908646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-13 01:49:19.908750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-13 01:49:20.056943: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/gloss2sent/gloss2sent.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:49:29.608818Z","iopub.execute_input":"2024-05-13T01:49:29.609347Z","iopub.status.idle":"2024-05-13T01:49:29.640315Z","shell.execute_reply.started":"2024-05-13T01:49:29.609321Z","shell.execute_reply":"2024-05-13T01:49:29.639430Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                       Glosses  \\\n0     loud dog barks excited quiet bird fence.   \n1          Happy cow grazes big green pasture.   \n2  Man short hat shields eyes bright sunlight.   \n3       Girl New cell phone explored features.   \n4                    Fan cools hot summer day.   \n\n                                           Sentences  \n0  The loud dog barks excitedly at the quiet bird...  \n1  The happy cow grazes peacefully in the big, gr...  \n2  He wears a short hat to shield his eyes from t...  \n3  She excitedly shows off her new cell phone, ea...  \n4  The fan hums softly as it cools the room on a ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Glosses</th>\n      <th>Sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>loud dog barks excited quiet bird fence.</td>\n      <td>The loud dog barks excitedly at the quiet bird...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Happy cow grazes big green pasture.</td>\n      <td>The happy cow grazes peacefully in the big, gr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Man short hat shields eyes bright sunlight.</td>\n      <td>He wears a short hat to shield his eyes from t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Girl New cell phone explored features.</td>\n      <td>She excitedly shows off her new cell phone, ea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fan cools hot summer day.</td>\n      <td>The fan hums softly as it cools the room on a ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:49:33.078993Z","iopub.execute_input":"2024-05-13T01:49:33.079366Z","iopub.status.idle":"2024-05-13T01:49:33.088793Z","shell.execute_reply.started":"2024-05-13T01:49:33.079319Z","shell.execute_reply":"2024-05-13T01:49:33.087838Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                       Glosses  \\\n0     loud dog barks excited quiet bird fence.   \n1          Happy cow grazes big green pasture.   \n2  Man short hat shields eyes bright sunlight.   \n3       Girl New cell phone explored features.   \n4                    Fan cools hot summer day.   \n\n                                           Sentences  \n0  The loud dog barks excitedly at the quiet bird...  \n1  The happy cow grazes peacefully in the big, gr...  \n2  He wears a short hat to shield his eyes from t...  \n3  She excitedly shows off her new cell phone, ea...  \n4  The fan hums softly as it cools the room on a ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Glosses</th>\n      <th>Sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>loud dog barks excited quiet bird fence.</td>\n      <td>The loud dog barks excitedly at the quiet bird...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Happy cow grazes big green pasture.</td>\n      <td>The happy cow grazes peacefully in the big, gr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Man short hat shields eyes bright sunlight.</td>\n      <td>He wears a short hat to shield his eyes from t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Girl New cell phone explored features.</td>\n      <td>She excitedly shows off her new cell phone, ea...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fan cools hot summer day.</td>\n      <td>The fan hums softly as it cools the room on a ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:50:18.881321Z","iopub.execute_input":"2024-05-13T01:50:18.881667Z","iopub.status.idle":"2024-05-13T01:50:18.886249Z","shell.execute_reply.started":"2024-05-13T01:50:18.881641Z","shell.execute_reply":"2024-05-13T01:50:18.885203Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:50:19.476196Z","iopub.execute_input":"2024-05-13T01:50:19.476863Z","iopub.status.idle":"2024-05-13T01:50:19.482654Z","shell.execute_reply.started":"2024-05-13T01:50:19.476830Z","shell.execute_reply":"2024-05-13T01:50:19.481653Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer\n\n# Splitting the data into training and validation sets\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Loading pre-trained tokenizer (e.g., BERT tokenizer)\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n\n# Defining a custom PyTorch Dataset class\nclass SignLanguageDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        gloss = self.data.iloc[0][\"Glosses\"]\n        sentence = self.data.iloc[0][\"Sentences\"]\n\n        # Tokenize gloss and sentence\n        inputs = self.tokenizer(gloss, sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n        \n        input_ids = inputs[\"input_ids\"].squeeze(0)\n        \n        attention_mask = inputs[\"attention_mask\"].squeeze(0)\n        \n\n        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n\n# Creating DataLoader objects for training and validation sets\ntrain_dataset = SignLanguageDataset(train_data, tokenizer)\nval_dataset = SignLanguageDataset(val_data, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:50:19.986720Z","iopub.execute_input":"2024-05-13T01:50:19.987058Z","iopub.status.idle":"2024-05-13T01:50:20.115314Z","shell.execute_reply.started":"2024-05-13T01:50:19.987031Z","shell.execute_reply":"2024-05-13T01:50:20.114490Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#student model \nimport torch.nn as nn\nfrom transformers import BertModel\nclass StudentModel(nn.Module):\n    def __init__(self):\n        super(StudentModel, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.fc = nn.Linear(self.bert.config.hidden_size, len(tokenizer.vocab))\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        logits = self.fc(outputs.last_hidden_state[:, 0, :])\n        return logits\nstudent_model = StudentModel()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:50:20.707700Z","iopub.execute_input":"2024-05-13T01:50:20.708031Z","iopub.status.idle":"2024-05-13T01:50:21.249414Z","shell.execute_reply.started":"2024-05-13T01:50:20.708007Z","shell.execute_reply":"2024-05-13T01:50:21.248622Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.nn.functional as F\n\n# Definin the temperature for knowledge distillation\ntemperature = 5.0  #adjustment based on preference\n\n\ncriterion = nn.KLDivLoss() #defining loss function\noptimizer = optim.AdamW(student_model.parameters(), lr=1e-5) # defining optimizer\n\n# Training loop\nfor epoch in range(7): #can be adjusted as per requirements\n    student_model.train()\n    for batch in train_loader:\n        input_ids = batch[\"input_ids\"]\n        attention_mask = batch[\"attention_mask\"]\n\n        # Forward pass: student model\n        logits_student = student_model(input_ids, attention_mask)\n\n        # Computing the knowledge distillation loss\n        kd_loss = criterion(F.log_softmax(logits_student / temperature, dim=-1),\n                            F.softmax(logits_student / temperature, dim=-1))\n\n        # Backpropagation and optimization\n        optimizer.zero_grad()\n        kd_loss.backward()\n        optimizer.step()\n\n    # Validation loop (evaluating the student model performance on validation set)\n    student_model.eval()\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch[\"input_ids\"]\n            attention_mask = batch[\"attention_mask\"]\n\n            # Forward pass\n            logits_student = student_model(input_ids, attention_mask)\n\n          # Next up, we can compute the validation metrics\n        validation_loss = compute_validation_loss(model, criterion, val_loader)\n        \n   \"\"\"\n   def compute_validation_loss(student_model, criterion, data_loader):\n            model.eval()\n            val_loss = 0.0\n            num_samples = 0\n            with torch.no_grad():\n            for batch in data_loader:\n                input_ids = batch[\"input_ids\"]\n                attention_mask = batch[\"attention_mask\"]\n                logits_student = model(input_ids, attention_mask)\n                labels = input_ids  # Assuming labels are the input_ids\n                batch_loss = criterion(logits_student, labels)\n                val_loss += batch_loss.item() * input_ids.size(0)\n                num_samples += input_ids.size(0)\n            return val_loss / num_samples\n\n# Printing the result\nprint(\"Validation Loss:\", validation_loss)\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T01:51:42.077852Z","iopub.execute_input":"2024-05-13T01:51:42.078512Z","iopub.status.idle":"2024-05-13T01:51:42.086228Z","shell.execute_reply.started":"2024-05-13T01:51:42.078480Z","shell.execute_reply":"2024-05-13T01:51:42.085093Z"},"trusted":true},"execution_count":23,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m<tokenize>:43\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"],"ename":"IndentationError","evalue":"unindent does not match any outer indentation level (<tokenize>, line 43)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}